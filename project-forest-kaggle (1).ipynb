{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8118924,"sourceType":"datasetVersion","datasetId":4797167}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split #imports the train_test_split function from scikit-learn’s model_selection module\nfrom sklearn.preprocessing import StandardScaler #loading in train_test_split function from scikit-learn’s model_selection module\nfrom sklearn.linear_model import Perceptron #loading in train_test_split function from scikit-learn’s model_selection module\nfrom sklearn.linear_model import LogisticRegression #loading in train_test_split function from scikit-learn’s model_selection module\nfrom sklearn.tree import DecisionTreeClassifier #loading in train_test_split function from scikit-learn’s model_selection module\nfrom sklearn.ensemble import RandomForestClassifier #loading in train_test_split function from scikit-learn’s model_selection module\nfrom sklearn.neighbors import KNeighborsClassifier #loading in train_test_split function from scikit-learn’s model_selection module\nfrom sklearn.metrics import accuracy_score, classification_report #loading in train_test_split function from scikit-learn’s model_selection module\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T01:43:21.354986Z","iopub.execute_input":"2024-04-17T01:43:21.355707Z","iopub.status.idle":"2024-04-17T01:43:24.047823Z","shell.execute_reply.started":"2024-04-17T01:43:21.355675Z","shell.execute_reply":"2024-04-17T01:43:24.047073Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/forest/train.csv\n/kaggle/input/forest/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/forest/train.csv') #import train data set as \"mydata\"","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:24.049274Z","iopub.execute_input":"2024-04-17T01:43:24.050473Z","iopub.status.idle":"2024-04-17T01:43:26.825256Z","shell.execute_reply.started":"2024-04-17T01:43:24.050436Z","shell.execute_reply":"2024-04-17T01:43:26.824210Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Part 2: Preprocessing and Feature Engineering**\n\nWe would use the \"drop\" function to drop the \"id\" column and set the axis to 1 and renaming the new dataset to \"train2\".","metadata":{}},{"cell_type":"code","source":"train2 = train.drop('id', axis=1)\ntrain2.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:26.831746Z","iopub.execute_input":"2024-04-17T01:43:26.832196Z","iopub.status.idle":"2024-04-17T01:43:26.930078Z","shell.execute_reply.started":"2024-04-17T01:43:26.832160Z","shell.execute_reply":"2024-04-17T01:43:26.929230Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n0       3031      38      8                               192   \n1       2717      66     14                               384   \n2       3172      24      9                               300   \n3       3089      67      2                               285   \n4       2569      22     20                               216   \n\n   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n0                              40                               30   \n1                             -19                              927   \n2                              27                             2389   \n3                             -37                             2424   \n4                              87                             1095   \n\n   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n0            220             223            138   \n1            233             211            108   \n2            215             220            141   \n3            221             235            151   \n4            204             194            121   \n\n   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n0                                1176  ...            1            0   \n1                                2452  ...            0            0   \n2                                2408  ...            0            0   \n3                                1745  ...            0            0   \n4                                1506  ...            0            0   \n\n   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n0            0            0            0            0            0   \n1            0            0            0            0            0   \n2            0            0            0            0            0   \n3            0            0            0            0            0   \n4            0            0            0            0            0   \n\n   Soil_Type39  Soil_Type40  label  \n0            0            0      2  \n1            0            0      2  \n2            0            0      1  \n3            0            0      2  \n4            0            0      2  \n\n[5 rows x 55 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Elevation</th>\n      <th>Aspect</th>\n      <th>Slope</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Vertical_Distance_To_Hydrology</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Hillshade_3pm</th>\n      <th>Horizontal_Distance_To_Fire_Points</th>\n      <th>...</th>\n      <th>Soil_Type32</th>\n      <th>Soil_Type33</th>\n      <th>Soil_Type34</th>\n      <th>Soil_Type35</th>\n      <th>Soil_Type36</th>\n      <th>Soil_Type37</th>\n      <th>Soil_Type38</th>\n      <th>Soil_Type39</th>\n      <th>Soil_Type40</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3031</td>\n      <td>38</td>\n      <td>8</td>\n      <td>192</td>\n      <td>40</td>\n      <td>30</td>\n      <td>220</td>\n      <td>223</td>\n      <td>138</td>\n      <td>1176</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2717</td>\n      <td>66</td>\n      <td>14</td>\n      <td>384</td>\n      <td>-19</td>\n      <td>927</td>\n      <td>233</td>\n      <td>211</td>\n      <td>108</td>\n      <td>2452</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3172</td>\n      <td>24</td>\n      <td>9</td>\n      <td>300</td>\n      <td>27</td>\n      <td>2389</td>\n      <td>215</td>\n      <td>220</td>\n      <td>141</td>\n      <td>2408</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3089</td>\n      <td>67</td>\n      <td>2</td>\n      <td>285</td>\n      <td>-37</td>\n      <td>2424</td>\n      <td>221</td>\n      <td>235</td>\n      <td>151</td>\n      <td>1745</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2569</td>\n      <td>22</td>\n      <td>20</td>\n      <td>216</td>\n      <td>87</td>\n      <td>1095</td>\n      <td>204</td>\n      <td>194</td>\n      <td>121</td>\n      <td>1506</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 55 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Next we need to create a new data set with the independent variables called \"X\" and then \"Y\" would be the target variable or prediction output.","metadata":{}},{"cell_type":"code","source":"X = train2.drop('label',axis=1) #independent variables\ny = train2['label'] #output","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:26.931506Z","iopub.execute_input":"2024-04-17T01:43:26.931837Z","iopub.status.idle":"2024-04-17T01:43:27.031664Z","shell.execute_reply.started":"2024-04-17T01:43:26.931810Z","shell.execute_reply":"2024-04-17T01:43:27.030586Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Now we are spliting the datset into 75% training and 25% testing.\n","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25, random_state=1) #spliting dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:27.033198Z","iopub.execute_input":"2024-04-17T01:43:27.033652Z","iopub.status.idle":"2024-04-17T01:43:27.323986Z","shell.execute_reply.started":"2024-04-17T01:43:27.033611Z","shell.execute_reply":"2024-04-17T01:43:27.322872Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"We need to ensure that both the training and test datasets are scaled in the same way, so the machine learning algorithms will perform effectively. ","metadata":{}},{"cell_type":"code","source":"sc = StandardScaler().fit(X_train) #StandardScaler computes the mean and standard deviation for each feature in \"X_train\"\nXtrain_stnd=sc.transform(X_train) #transforms (scales) the training data\nXtest_stnd=sc.transform(X_test) #transforms (scales) the test data X_test ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:27.325551Z","iopub.execute_input":"2024-04-17T01:43:27.326023Z","iopub.status.idle":"2024-04-17T01:43:27.726171Z","shell.execute_reply.started":"2024-04-17T01:43:27.325986Z","shell.execute_reply":"2024-04-17T01:43:27.724969Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Part 3: Model Training and Evaluation:**\n\nHere we building and using different models such as perceptron, logistic regression, support vector machines (SVM), decision tree, k-nearest neighbors (KNN), and random forest to evaluate each accuracy of the predictions. We are going to use the training and testing data set \"Xtrain_stnd\" and \"Xtest_stnd\" we just created.","metadata":{}},{"cell_type":"code","source":"#Perceptron model\n\nprecept = Perceptron(eta0=0.1, random_state=1).fit(Xtrain_stnd, y_train) #building perceptron model\nypre_pred = precept.predict(Xtest_stnd) #testing the model\n\naccuracy = accuracy_score(y_test, ypre_pred) #calculating accuracy \nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:27.734899Z","iopub.execute_input":"2024-04-17T01:43:27.735195Z","iopub.status.idle":"2024-04-17T01:43:33.053975Z","shell.execute_reply.started":"2024-04-17T01:43:27.735171Z","shell.execute_reply":"2024-04-17T01:43:33.048620Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Accuracy: 0.6242265690214538\n","output_type":"stream"}]},{"cell_type":"code","source":"#Decision Tree model\n\ndectree = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=1).fit(Xtrain_stnd, y_train) #building Decision Treee model\nyddectree_pred = dectree.predict(Xtest_stnd) #testing the model\n\naccuracy = accuracy_score(y_test, yddectree_pred) #calculating accuracy \nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:33.057931Z","iopub.execute_input":"2024-04-17T01:43:33.058602Z","iopub.status.idle":"2024-04-17T01:43:35.434586Z","shell.execute_reply.started":"2024-04-17T01:43:33.058564Z","shell.execute_reply":"2024-04-17T01:43:35.433237Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Accuracy: 0.7029508704594546\n","output_type":"stream"}]},{"cell_type":"code","source":"#K-nearest neighbors (KNN)\n\nknn = KNeighborsClassifier(n_neighbors=5, p=1, metric='euclidean').fit(Xtrain_stnd, y_train) #building K-nearest neighbors (KNN)\nyknn_pred = knn.predict(Xtest_stnd) #testing the model\n\naccuracy = accuracy_score(y_test, yknn_pred) #calculating accuracy \nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:43:35.436178Z","iopub.execute_input":"2024-04-17T01:43:35.436717Z","iopub.status.idle":"2024-04-17T01:45:55.544812Z","shell.execute_reply.started":"2024-04-17T01:43:35.436668Z","shell.execute_reply":"2024-04-17T01:45:55.543547Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy: 0.9209228677400756\n","output_type":"stream"}]},{"cell_type":"code","source":"#Random Forest model\n\nrfc = RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=2).fit(Xtrain_stnd, y_train)  #building Random Forest model\nyrfc_pred = rfc.predict(Xtest_stnd) #testing the model\n\naccuracy = accuracy_score(y_test, yrfc_pred) #calculating accuracy \nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:45:55.546259Z","iopub.execute_input":"2024-04-17T01:45:55.546557Z","iopub.status.idle":"2024-04-17T01:46:56.878570Z","shell.execute_reply.started":"2024-04-17T01:45:55.546534Z","shell.execute_reply":"2024-04-17T01:46:56.877610Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Accuracy: 0.9503971498154092\n","output_type":"stream"}]},{"cell_type":"code","source":"#Logistic regression model\n\nlr = LogisticRegression(max_iter=4000, random_state=1).fit(Xtrain_stnd, y_train) #building logistic regression model\nylr_pred = lr.predict(Xtest_stnd) #testing the model\n\naccuracy = accuracy_score(y_test, ylr_pred) #calculating accuracy \nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:46:56.879678Z","iopub.execute_input":"2024-04-17T01:46:56.880002Z","iopub.status.idle":"2024-04-17T01:50:49.026477Z","shell.execute_reply.started":"2024-04-17T01:46:56.879973Z","shell.execute_reply":"2024-04-17T01:50:49.025057Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy: 0.7258590569950862\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Part 4: Model Deployment and Submission**\n","metadata":{}},{"cell_type":"markdown","source":"Now we use the Random Forest model as our final model becuse it produces the highest accuracy of 0.9503971498154092 compared to the other models. We would also need to produce a submission excel sheet with the prediction/outcome of the \"test\" datset.","metadata":{}},{"cell_type":"code","source":"test4 = pd.read_csv('/kaggle/input/forest/test.csv') #import test dataset\n\n\ntest6 = test4.drop('id', axis=1) # drop the \"id\" column\n\n\nsc3 = StandardScaler().fit(test6)  #StandardScaler computes the mean and standard deviation for each feature in \"X_TestEnc\"\nsc2 = sc3.transform(test6) #transforms (scales) the X_TestEnc data\n\nyrfc2_pred = rfc.predict(sc2) #testing the model\n\nsubmission_df = pd.DataFrame({ #creating a DataFrame called submission_df with two columns \"id\" and \"label\". \n    \"id\": test4['id'],  \n    \"label\": yrfc2_pred        #\"label\" contains the outputs/prediction from \"yrfc2_pred\" made from the Random Forest model\n}) \n\nsubmission_df.to_csv(\"submission.csv\", index=False) #saves the contents of \"submission_df\" toa CSV file named \"submission.csv\" without including he index column","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:50:49.028485Z","iopub.execute_input":"2024-04-17T01:50:49.029307Z","iopub.status.idle":"2024-04-17T01:50:52.482949Z","shell.execute_reply.started":"2024-04-17T01:50:49.029256Z","shell.execute_reply":"2024-04-17T01:50:52.482078Z"},"trusted":true},"execution_count":13,"outputs":[]}]}